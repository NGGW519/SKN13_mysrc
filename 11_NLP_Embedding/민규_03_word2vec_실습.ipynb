{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fa1505-5df4-415a-b490-73573300ae62",
   "metadata": {},
   "source": [
    "# Gensim 패키지\n",
    "- Python으로 작성된 오픈 소스 라이브러리로, 자연어 처리와 관련된 다양한 기능을 제공한다.\n",
    "- 주요 기능\n",
    "    - **Word Embeddings**\n",
    "        - word2vec, fastext, doc2vec 등 다양한 word embedding 모델을 제공\n",
    "    - **토픽 모델링 (Topic Modeling)**\n",
    "        - LDA등 문장의 주제를 파악하는 모델 제공\n",
    "    - **텍스트/word 유사도 계산**\n",
    "    - **문서 군집화**\n",
    "        - 비슷한 주제의 문서들을 군집화.\n",
    "    - 다양한 dataset과 pretrained model 제공\n",
    "        - https://github.com/piskvorky/gensim-data\n",
    "- https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb22fe8-39a2-493b-90d1-6eb59884bfbe",
   "metadata": {},
   "source": [
    "## 설치\n",
    "- `pip install gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b915158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\playdata\\miniconda3\\envs\\dl\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\playdata\\miniconda3\\envs\\dl\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\playdata\\miniconda3\\envs\\dl\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\playdata\\miniconda3\\envs\\dl\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\playdata\\miniconda3\\envs\\dl\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22013f4-94ed-4cba-8d86-31836ba16af1",
   "metadata": {},
   "source": [
    "# Word2Vec 학습\n",
    "\n",
    "- gensim.models.Word2Vec\n",
    "- 주요 파라미터\n",
    "    - sentences\n",
    "        -  학습에 사용할 문서의 리스트. 각 문서의 단어들을 리스트로 묶고 그 문서들을 리스트로 묶은 중첩 리스트.\n",
    "        - 예시: \\[\\['word1', 'word2', 'word3'], \\['word4', 'word5']]\n",
    "    - vector_size\n",
    "        -  embedding vector 크기. 기본값: 100\n",
    "    - window\n",
    "        -  context window 크기. 중심단어를 기준으로 좌우 몇개의 단어를 확인하는지 크기. 기본값: 5\n",
    "    - min_count\n",
    "        - 이 설정보다 낮은 빈도로 등장하는 단어는 무시한다. 데이터 노이즈를 줄이는데 도움이된다. 기본값: 5\n",
    "    - sg\n",
    "        - 모델 아키텍처 결정.\n",
    "        - `0`: CBOW, `1`: Skip-gram. 기본값: 0\n",
    "    - epochs\n",
    "        - epochs 수 설정. 기본값: 5\n",
    "    - alpha\n",
    "        - initial leaning rate. 기본값: 0.025\n",
    "    - min_alpha\n",
    "        - 최소 learning rate. 기본값: 0.0001\n",
    "        - epoch 마다 learning rate를 alpha 에서 min_alpha 까지 선형적으로 줄여나간다.\n",
    "    - workers\n",
    "        -  사용 Thread 수. 기본값: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f350467-b0c2-46fa-b1f7-e2c57a4bf439",
   "metadata": {},
   "source": [
    "## 학습(Train)\n",
    "1. Word2Vec 의 initializer에 sentences를 넣어 한번에 학습한다.\n",
    "2. Word2Vec 클래스에 학습 설정을 하고 `train()` 메소드를 이용해 학습한다.\n",
    "    - epoch 단위로 작업을 할 경우 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a02a4e9-2d24-4ede-8395-0482661809a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 텍스트 데이터\n",
    "sentences = [\n",
    "    \"Natural language processing is an exciting field of study\",\n",
    "    \"Word embeddings are a type of word representation\",\n",
    "    \"Gensim is a powerful library for text processing\",\n",
    "    \"Word2Vec creates vector representations of words\", \n",
    "    \"Gensim runs on Linux, Windows and OS X, as well as any other platform that supports Python and NumPy.\"\n",
    "    \"All Gensim source code is hosted on Github under the GNU LGPL license, maintained by its open source community.\",\n",
    "    \"For commercial arrangements, see Business Support.\",\n",
    "    \"Gensim can process arbitrarily large corpora, using data-streamed algorithms.\",\n",
    "    \"There are no \\\"dataset must fit in RAM\\\" limitations.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b455f3f-def9-487e-a3a4-f9563562e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "def tokenizer(docs):\n",
    "\t# 소문자로 모두 변환\n",
    "\t# 알파벳, 순자, _를 제외한 모든 문자들을 제거\n",
    "\t# 단어(어절) 단위 토큰화\n",
    "\treturn [ nltk.word_tokenize(re.sub(r\"[^\\w\\s]\", \" \", doc.lower())) for doc in docs]\n",
    "\n",
    "# [^\\w] - \\w를 제외한 나머지 ^들을 찾아라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c14e0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['naturallanguageprocessingisanexcitingfieldofstudy'],\n",
       " ['wordembeddingsareatypeofwordrepresentation'],\n",
       " ['gensimisapowerfullibraryfortextprocessing'],\n",
       " ['word2veccreatesvectorrepresentationsofwords'],\n",
       " ['gensimrunsonlinuxwindowsandosxaswellasanyotherplatformthatsupportspythonandnumpyallgensimsourcecodeishostedongithubunderthegnulgpllicensemaintainedbyitsopensourcecommunity'],\n",
       " ['forcommercialarrangementsseebusinesssupport'],\n",
       " ['gensimcanprocessarbitrarilylargecorporausingdatastreamedalgorithms'],\n",
       " ['therearenodatasetmustfitinramlimitations']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[nltk.word_tokenize(re.sub(r\"[^\\w]\", \"\", doc.lower())) for doc in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f3a73dc-943f-4baa-a072-c9b30ea482e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'is',\n",
       "  'an',\n",
       "  'exciting',\n",
       "  'field',\n",
       "  'of',\n",
       "  'study'],\n",
       " ['word', 'embeddings', 'are', 'a', 'type', 'of', 'word', 'representation'],\n",
       " ['gensim', 'is', 'a', 'powerful', 'library', 'for', 'text', 'processing'],\n",
       " ['word2vec', 'creates', 'vector', 'representations', 'of', 'words'],\n",
       " ['gensim',\n",
       "  'runs',\n",
       "  'on',\n",
       "  'linux',\n",
       "  'windows',\n",
       "  'and',\n",
       "  'os',\n",
       "  'x',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'any',\n",
       "  'other',\n",
       "  'platform',\n",
       "  'that',\n",
       "  'supports',\n",
       "  'python',\n",
       "  'and',\n",
       "  'numpy',\n",
       "  'all',\n",
       "  'gensim',\n",
       "  'source',\n",
       "  'code',\n",
       "  'is',\n",
       "  'hosted',\n",
       "  'on',\n",
       "  'github',\n",
       "  'under',\n",
       "  'the',\n",
       "  'gnu',\n",
       "  'lgpl',\n",
       "  'license',\n",
       "  'maintained',\n",
       "  'by',\n",
       "  'its',\n",
       "  'open',\n",
       "  'source',\n",
       "  'community'],\n",
       " ['for', 'commercial', 'arrangements', 'see', 'business', 'support'],\n",
       " ['gensim',\n",
       "  'can',\n",
       "  'process',\n",
       "  'arbitrarily',\n",
       "  'large',\n",
       "  'corpora',\n",
       "  'using',\n",
       "  'data',\n",
       "  'streamed',\n",
       "  'algorithms'],\n",
       " ['there', 'are', 'no', 'dataset', 'must', 'fit', 'in', 'ram', 'limitations']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(sentences)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c33d8473-e106-4d7e-b115-b0072833efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "## Word2Vec 객체를 생성 : 학습data, epoch -> 객체 생성할 때 모델을 학습, 학습결과 모델을 반환.\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "model1 = Word2Vec(\n",
    "\tsentences=tokens,\t# 학습 시킬 data\n",
    "\tvector_size=10,\t\t# embedding vector의 차원(한개 단어에서 몇개 feature를 추출할지)\n",
    "\twindow=2,\t\t\t# window size (주변 단어의 개수)\n",
    "\tmin_count=1,\n",
    "\tepochs=10,\n",
    "\tworkers=os.cpu_count()\t# 병렬처리 개수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85cd6603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch loss :  151.93861389160156\n",
      "1 epoch loss :  121.71185302734375\n",
      "2 epoch loss :  109.64387512207031\n",
      "3 epoch loss :  135.7916259765625\n",
      "4 epoch loss :  176.20217895507812\n",
      "5 epoch loss :  154.9056396484375\n",
      "6 epoch loss :  150.0056915283203\n",
      "7 epoch loss :  122.36213684082031\n",
      "8 epoch loss :  143.60386657714844\n",
      "9 epoch loss :  166.28038024902344\n"
     ]
    }
   ],
   "source": [
    "# 학습data, epoch를 설정하지 않음 -> 학습되지 않은 모델 반환\n",
    "model2 = Word2Vec(\n",
    "\tvector_size=10,\n",
    "\twindow=2,\n",
    "\tmin_count=1,\n",
    "\tworkers=os.cpu_count()\n",
    ")\n",
    "# model에 vocab을 설정\n",
    "model2.build_vocab(tokens)\n",
    "# 학습\n",
    "epoch = 10\n",
    "for e in range(epoch):\n",
    "\tmodel2.train(\n",
    "\t\ttokens,\t\t# 학습data\n",
    "\t\ttotal_examples=model2.corpus_count,\t\t# 학습data(문서) 개수\n",
    "\t\tepochs=1,\n",
    "\t\tcompute_loss=True\n",
    "\t)\n",
    "\tloss = model2.get_latest_training_loss()\n",
    "\tprint(f\"{e} epoch loss :  {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fd7bb-3e14-49c2-9abe-5f3663f481a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad7fe805-022b-4e1a-b0ea-8e5bc692fa75",
   "metadata": {},
   "source": [
    "## 학습 후 결과 조회\n",
    "\n",
    "- **KeyedVectors 조회**\n",
    "    - KeyedVectors는 단어와 vector를 매핑한 객체로 embedding vector를 이용한 다양한 조회를 지원한다.\n",
    "    - model.wv 로 조회해서 사용.\n",
    "- **Embedding Vector 조회**\n",
    "  - model.wv.vectors\n",
    "- **단어 목록 조회**\n",
    "    - model.wv.index_to_key, model.wv.key_to_index\n",
    "- **단어 벡터 조회**\n",
    "    - model.wv[word]: 특정 단어의 vector반환\n",
    "- **Vocab에 대상 단어가 있는지 확인**\n",
    "    - \"대상단어\" in model.wv\n",
    "- **유사단어들 찾기**\n",
    "    - model.wv.most_similar(word)\n",
    "- **단어간 유사도 비교**\n",
    "    - model.wv.similarity(word1, word2)\n",
    "- 유사도를 계산할 때 **코사인 유사도(Cosine Similarity)** 를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba473d91",
   "metadata": {},
   "source": [
    "> # 코사인 유사도\n",
    "> - 두 벡터 간의 유사성을 측정하는 중요한 방법 중 하나.\n",
    "> - 코사인 유사도는 두 벡터 간의 코사인 각도를 이용하여 유사도를 계산한다. 이때 벡터의 **크기는 결과에 영향을 미치지 않고, 오직 방향만이 중요**하다.\n",
    "> ## 공식\n",
    "> \n",
    "> $$ similarity = cos(\\theta) = \\frac{A⋅B}{||A||\\ ||B||} = \\frac{\\sum_{i=1}^{n}{A_i×B_i}}{\\sqrt{\\sum_{i=1}^{n}(A_i)^2}×\\sqrt{\\sum_{i=1}^{n}(B_i)^2}} $$\n",
    "> \n",
    "> ## 결과 해석\n",
    "> \n",
    "> - **값의 범위**: -1에서 1 사이의 값을 가집니다\n",
    ">   - 1: 두 벡터가 완전히 동일한 방향 (0도의 cosine 값)\n",
    ">   - 0: 두 벡터가 직교 (90도의 cosine 값)\n",
    ">   - -1: 두 벡터가 정반대 방향 (180도의 cosine 값)\n",
    "> \n",
    "> ![cosine_similarity](figures/gensim_consin_sim.png)\n",
    ">\n",
    "> ## Python 코사인 유사도 계산\n",
    "> ```python\n",
    "> from numpy import dot\n",
    "> from numpy.linalg import norm\n",
    "> \n",
    "> def cosine_similarity(A, B):\n",
    ">     return dot(A, B)/(norm(A)*norm(B))\n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c5d0e0b-0d18-40ac-91c4-11e9114acbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x2a3ca45e9f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv\t# KeyedVectors -> token-embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b560fbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gensim',\n",
       " 'is',\n",
       " 'of',\n",
       " 'for',\n",
       " 'processing',\n",
       " 'source',\n",
       " 'on',\n",
       " 'as',\n",
       " 'word',\n",
       " 'are',\n",
       " 'a',\n",
       " 'and',\n",
       " 'words',\n",
       " 'runs',\n",
       " 'linux',\n",
       " 'windows',\n",
       " 'x',\n",
       " 'os',\n",
       " 'vector',\n",
       " 'well',\n",
       " 'any',\n",
       " 'other',\n",
       " 'representations',\n",
       " 'limitations',\n",
       " 'creates',\n",
       " 'word2vec',\n",
       " 'text',\n",
       " 'that',\n",
       " 'library',\n",
       " 'powerful',\n",
       " 'representation',\n",
       " 'type',\n",
       " 'embeddings',\n",
       " 'study',\n",
       " 'field',\n",
       " 'exciting',\n",
       " 'an',\n",
       " 'language',\n",
       " 'platform',\n",
       " 'supports',\n",
       " 'ram',\n",
       " 'data',\n",
       " 'support',\n",
       " 'can',\n",
       " 'process',\n",
       " 'arbitrarily',\n",
       " 'large',\n",
       " 'corpora',\n",
       " 'using',\n",
       " 'streamed',\n",
       " 'python',\n",
       " 'algorithms',\n",
       " 'there',\n",
       " 'no',\n",
       " 'dataset',\n",
       " 'must',\n",
       " 'fit',\n",
       " 'in',\n",
       " 'business',\n",
       " 'see',\n",
       " 'arrangements',\n",
       " 'commercial',\n",
       " 'numpy',\n",
       " 'all',\n",
       " 'code',\n",
       " 'hosted',\n",
       " 'github',\n",
       " 'under',\n",
       " 'the',\n",
       " 'gnu',\n",
       " 'lgpl',\n",
       " 'license',\n",
       " 'maintained',\n",
       " 'by',\n",
       " 'its',\n",
       " 'open',\n",
       " 'community',\n",
       " 'natural']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.index_to_key\t# vocab : token_id -> token(단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "956bbab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00524791,  0.00244228,  0.05116045,  0.09009441, -0.09281229,\n",
       "       -0.0712302 ,  0.06483191,  0.08985646, -0.05037782, -0.03772063],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 단어의 embedding vector를 조회\n",
    "model1.wv[\"gensim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36df1892-1804-4f23-a396-b52f82238d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model1.wv[\"안녕\"]\n",
    "\"안녕\" in model1.wv, \"gensim\" in model1.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9607cc94-67cf-4a87-8a42-ab88683cd514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "없는뎁쇼\n"
     ]
    }
   ],
   "source": [
    "word = \"안녕\"\n",
    "if word in model1.wv:\n",
    "\tprint(model1.wv[word])\n",
    "else:\n",
    "\tprint(\"없는뎁쇼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c3c06ac-5bb3-4a2f-b0ac-d1aa0c747f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('commercial', 0.7190989851951599),\n",
       " ('embeddings', 0.7149730324745178),\n",
       " ('platform', 0.670430600643158),\n",
       " ('support', 0.6412696838378906),\n",
       " ('using', 0.596753716468811),\n",
       " ('is', 0.5443570613861084),\n",
       " ('language', 0.5327599048614502),\n",
       " ('lgpl', 0.5187968015670776),\n",
       " ('other', 0.5120983123779297),\n",
       " ('must', 0.5062717199325562)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 검사\n",
    "model1.wv.most_similar(\"gensim\")\t# gensim과 가장 유사한 단어를 순서대로 10개를 반환.\n",
    "# (단어, 유사도) 유사도 : -1 ~ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbcc828a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31715336"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어간의 유사도\n",
    "model1.wv.similarity(\"gensim\", \"study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de32ef-2dc7-49a6-b829-68b14f797267",
   "metadata": {},
   "source": [
    "## 모델 저장 및 로딩\n",
    "\n",
    "### 모델 저장, 로딩\n",
    "- `model.save('저장파일 경로')`\n",
    "  - gensim 자체 포맷으로 저장된다.\n",
    "- `gensim.models.Word2Vec.load('저장파일 경로')`\n",
    "  - `model.save()`로 저장된 모델을 Loading한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b9517b7-ee62-4313-a78e-42d5240cb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "model1.save(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1f55800-3dd3-4054-9c07-d48961518099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "load_model = Word2Vec.load(\"saved_models/w2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52c6ec17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('commercial', 0.7190989851951599),\n",
       " ('embeddings', 0.7149730324745178),\n",
       " ('platform', 0.670430600643158),\n",
       " ('support', 0.6412696838378906),\n",
       " ('using', 0.596753716468811),\n",
       " ('is', 0.5443570613861084),\n",
       " ('language', 0.5327599048614502),\n",
       " ('lgpl', 0.5187968015670776),\n",
       " ('other', 0.5120983123779297),\n",
       " ('must', 0.5062717199325562)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.wv.most_similar(\"gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34742583-58b5-40c8-b3ab-a641147cdd07",
   "metadata": {},
   "source": [
    "### Word Embedding Vector만 저장 및 로드\n",
    "- `KeyedVectors` 를 이용해 저장한다.\n",
    "    - `model.wv.save_word2vec_format('저장경로', binary=True|False)`\n",
    "        - binary=True: binary 파일로 저장한다. 용량이 작은 대신 내용확인이 안된다.\n",
    "        - binary=False: csv(공백구분자) 형식 text로 저장한다. 내용을 확인할 수있지만 파일용량이 크다.\n",
    "- `KeyedVectors.load_word2vec_format(\"저장경로\", binary=True|False)`\n",
    "    - 저장시 binary에 맞춰 읽는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9dfab01-5ed0-4749-a585-fb26ba817495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)\n",
    "model1.wv.save_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "114fe1da-cf7d-411d-a46a-8d69045df1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "load_wv_bin = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a72063a1-afa5-4c69-b271-982d1f185843",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_wv_csv = KeyedVectors.load_word2vec_format(\"saved_models/keyedvector.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "791aeff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('commercial', 0.7190989851951599),\n",
       "  ('embeddings', 0.7149730324745178),\n",
       "  ('platform', 0.670430600643158),\n",
       "  ('support', 0.6412696838378906),\n",
       "  ('using', 0.596753716468811),\n",
       "  ('is', 0.5443570613861084),\n",
       "  ('language', 0.5327599048614502),\n",
       "  ('lgpl', 0.5187968015670776),\n",
       "  ('other', 0.5120983123779297),\n",
       "  ('must', 0.5062717199325562)],\n",
       " [('commercial', 0.7190989851951599),\n",
       "  ('embeddings', 0.7149730324745178),\n",
       "  ('platform', 0.670430600643158),\n",
       "  ('support', 0.6412696838378906),\n",
       "  ('using', 0.596753716468811),\n",
       "  ('is', 0.5443570613861084),\n",
       "  ('language', 0.5327599048614502),\n",
       "  ('lgpl', 0.5187968015670776),\n",
       "  ('other', 0.5120983123779297),\n",
       "  ('must', 0.5062717199325562)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_wv_bin.most_similar(\"gensim\")\\\n",
    ",load_wv_csv.most_similar(\"gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b7152-2745-4e30-bc6f-5e417ab25f00",
   "metadata": {},
   "source": [
    "## Pretrained 모델 사용하기\n",
    "- https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc4f7b0a-8620-4c34-b463-3c186a70c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(\"ko_new.zip\") as zf:\t# 압축풀 파일경로\n",
    "\tzf.extractall(\"saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52eab43d-4df0-44b6-a531-83f66c427996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_wv = KeyedVectors.load_word2vec_format(\n",
    "\t\"saved_models/ko_new.txt\",\n",
    "\tbinary=False,\n",
    "\tencoding=\"utf-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7907d09e-8fd1-4462-9679-ca182617e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아침', 0.8432561755180359),\n",
       " ('밤', 0.7863156199455261),\n",
       " ('새벽', 0.7520349025726318),\n",
       " ('점심', 0.7118877172470093),\n",
       " ('그날', 0.7105917930603027)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"저녁\"\n",
    "ko_wv.most_similar(word, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39acd566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('토끼', 0.7924245595932007),\n",
       " ('원숭이', 0.7570016384124756),\n",
       " ('강아지', 0.7290453314781189),\n",
       " ('돼지', 0.7203201651573181),\n",
       " ('개구리', 0.7201221585273743)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"고양이\"\n",
    "ko_wv.most_similar(word, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a270cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.58721089e+00, -1.19083822e+00,  1.02693021e-01,  1.05791342e+00,\n",
       "       -1.73088193e+00, -4.92587328e-01,  8.28979313e-02,  1.45242226e+00,\n",
       "        4.42151427e-01,  1.04589748e+00,  1.58645189e+00, -2.61376482e-02,\n",
       "        7.69314170e-01, -6.12096429e-01,  6.56534851e-01, -2.26123586e-01,\n",
       "        1.21184312e-01,  5.99661052e-01,  2.25671366e-01, -4.77610305e-02,\n",
       "        2.63381600e-01, -6.49069011e-01,  1.18908465e+00,  4.88096587e-02,\n",
       "       -1.52377498e+00, -1.48020709e+00,  3.10603404e+00,  1.54245174e+00,\n",
       "       -8.71144652e-01, -2.23441815e+00,  1.07638526e+00,  4.66621995e-01,\n",
       "        7.28348494e-01,  5.73255599e-01,  9.95010138e-01, -3.12950701e-01,\n",
       "       -6.26514375e-01,  2.04808339e-01, -6.00185513e-01,  3.69779378e-01,\n",
       "       -9.71896052e-01,  9.54610109e-01, -8.31314862e-01, -2.02365565e+00,\n",
       "       -2.81403124e-01, -1.29902530e+00, -7.05994308e-01, -1.24507181e-01,\n",
       "       -7.72656918e-01, -4.92854789e-02,  6.53591275e-01,  7.93715358e-01,\n",
       "       -2.32166261e-03,  4.14393306e-01, -2.05512714e+00, -3.37383002e-01,\n",
       "       -9.77245152e-01,  1.17383800e-01,  2.78027594e-01,  8.36566091e-01,\n",
       "        2.04441145e-01,  6.39230967e-01, -2.39022493e-01, -1.19986892e+00,\n",
       "        4.77629751e-01,  2.99206316e-01,  2.29924679e-01,  1.50265515e-01,\n",
       "        7.37724423e-01,  8.39603961e-01,  1.04578006e+00, -6.14199340e-01,\n",
       "       -1.20943710e-01,  4.92690593e-01,  1.51734293e+00, -1.15687335e+00,\n",
       "       -4.92789060e-01,  1.06846654e+00, -8.46203625e-01, -8.58228922e-01,\n",
       "        1.14440501e+00, -7.88520277e-01,  1.32777596e+00, -1.21479726e+00,\n",
       "       -2.14364719e+00, -6.49530768e-01, -3.14929456e-01, -5.31512022e-01,\n",
       "       -1.05130601e+00,  1.43782234e+00,  1.69859678e-02, -1.39322937e+00,\n",
       "       -8.79572332e-01, -1.12631094e+00,  7.72234797e-01,  9.42741394e-01,\n",
       "        9.18343544e-01,  6.29079044e-01,  1.25413644e+00,  2.77361423e-01,\n",
       "       -6.15891933e-01,  5.06046176e-01,  9.86464620e-01, -8.84694099e-01,\n",
       "       -2.48845369e-01, -1.65654689e-01, -1.84368208e-01, -7.10237801e-01,\n",
       "        7.00731426e-02, -3.04706618e-02,  2.40326381e+00,  4.80528921e-01,\n",
       "       -4.74073552e-02, -1.21438169e+00, -9.65048492e-01, -1.67920128e-01,\n",
       "        8.29936564e-01, -1.14859545e+00,  5.64489424e-01,  5.90726078e-01,\n",
       "        7.50666440e-01,  2.32355848e-01, -1.07395399e+00, -2.34621096e+00,\n",
       "        7.84997702e-01,  8.13206017e-01, -1.52594781e+00, -1.19561696e+00,\n",
       "        3.85164738e-01,  6.12635672e-01,  6.13197625e-01,  4.50155139e-01,\n",
       "        4.51780200e-01,  2.40641570e+00,  2.64069724e+00, -2.65938252e-01,\n",
       "        2.64825046e-01, -1.02699971e+00,  5.31768128e-02, -1.37471306e+00,\n",
       "        4.93015856e-01, -8.66602838e-01,  4.54439461e-01, -8.63911510e-01,\n",
       "        2.08070087e+00, -2.36849591e-01,  5.39233088e-01, -7.11860597e-01,\n",
       "       -8.94051850e-01, -7.05624640e-01, -5.66361070e-01,  7.50745535e-01,\n",
       "        1.13472354e-03, -2.59964075e-02,  7.15921164e-01, -8.76369178e-01,\n",
       "        3.35227251e-01,  1.13361204e+00, -7.52132118e-01, -4.75091279e-01,\n",
       "       -5.66046834e-01, -1.81995046e+00, -3.08129221e-01, -2.79548383e+00,\n",
       "       -1.14942968e+00, -1.84629083e+00,  1.17562652e+00,  1.05138734e-01,\n",
       "       -1.71807909e+00,  3.69065136e-01, -1.83372605e+00,  2.58956850e-01,\n",
       "        4.39346321e-02,  1.13649035e+00, -1.19913602e+00, -7.40754485e-01,\n",
       "        3.41195911e-01, -3.54268551e-01, -1.02949776e-01, -1.88555062e-01,\n",
       "       -1.08293128e+00, -3.50589752e-01,  1.88072145e+00,  1.11933839e+00,\n",
       "        5.86183667e-01,  1.47418547e+00, -7.68811628e-02,  1.41522735e-01,\n",
       "        4.21723798e-02,  1.79532409e+00,  6.37477636e-01,  1.01902139e+00,\n",
       "       -1.44701088e-02, -1.14796722e+00, -1.09180510e-01,  1.34468526e-01,\n",
       "        5.38899720e-01,  1.96584716e-01,  2.44551197e-01, -1.80794001e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb37baa",
   "metadata": {},
   "source": [
    "# 빅카인즈 뉴스 데이터를 이용한 Word2Vec 학습\n",
    "- 빅카인즈\n",
    "    - 한국언론진흥재단에서 운영하는 뉴스빅데이터 분석 서비스 사이트\n",
    "- 빅카인즈에서 특정 분야의 기사들을 수집해서 학습시킨다.\n",
    "    - https://www.bigkinds.or.kr/\n",
    "    - 회원가입 (구글, 네이버, 카카오 계정으로 가입 가능) 후 로그인\n",
    "    - 뉴스분석 > 뉴스검색$\\cdot$분석 클릭\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds1.png)\n",
    "    - 기간, 언론사, 분류, 상세검색 등 검색 조건입력 후 조회\n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds2.png)\n",
    "    - 결과 다운로드\n",
    "        - step3 분석결과및 시각화 -> 맨 아래 `엑셀다운로드` 클릭 \n",
    "    ![word2vec_bigkinds1.png](figures/word2vec_bigkinds3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d85c57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3d0d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\envs\\dl\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"NewsResult_20250223-20250523.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b573254c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2303, 19)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "819e80c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2303 entries, 0 to 2302\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   뉴스 식별자             2303 non-null   float64\n",
      " 1   일자                 2303 non-null   int64  \n",
      " 2   언론사                2303 non-null   object \n",
      " 3   기고자                1910 non-null   object \n",
      " 4   제목                 2303 non-null   object \n",
      " 5   통합 분류1             2303 non-null   object \n",
      " 6   통합 분류2             1933 non-null   object \n",
      " 7   통합 분류3             1664 non-null   object \n",
      " 8   사건/사고 분류1          2303 non-null   object \n",
      " 9   사건/사고 분류2          938 non-null    object \n",
      " 10  사건/사고 분류3          307 non-null    object \n",
      " 11  인물                 1390 non-null   object \n",
      " 12  위치                 2254 non-null   object \n",
      " 13  기관                 2247 non-null   object \n",
      " 14  키워드                2303 non-null   object \n",
      " 15  특성추출(가중치순 상위 50개)  2303 non-null   object \n",
      " 16  본문                 2303 non-null   object \n",
      " 17  URL                2256 non-null   object \n",
      " 18  분석제외 여부            60 non-null     object \n",
      "dtypes: float64(1), int64(1), object(17)\n",
      "memory usage: 342.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4771754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>뉴스 식별자</th>\n",
       "      <th>일자</th>\n",
       "      <th>언론사</th>\n",
       "      <th>기고자</th>\n",
       "      <th>제목</th>\n",
       "      <th>통합 분류1</th>\n",
       "      <th>통합 분류2</th>\n",
       "      <th>통합 분류3</th>\n",
       "      <th>사건/사고 분류1</th>\n",
       "      <th>사건/사고 분류2</th>\n",
       "      <th>사건/사고 분류3</th>\n",
       "      <th>인물</th>\n",
       "      <th>위치</th>\n",
       "      <th>기관</th>\n",
       "      <th>키워드</th>\n",
       "      <th>특성추출(가중치순 상위 50개)</th>\n",
       "      <th>본문</th>\n",
       "      <th>URL</th>\n",
       "      <th>분석제외 여부</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.101001e+06</td>\n",
       "      <td>20250523</td>\n",
       "      <td>한겨레</td>\n",
       "      <td>김남일 기자</td>\n",
       "      <td>검사 판사가 유권자 결정 바꾸는 선거법 ‘삭제→부활→삭제’ 30년사</td>\n",
       "      <td>정치&gt;국회_정당</td>\n",
       "      <td>사회&gt;사건_사고</td>\n",
       "      <td>정치&gt;선거</td>\n",
       "      <td>범죄&gt;기업범죄&gt;거래제한</td>\n",
       "      <td>재해&gt;자연재해&gt;홍수</td>\n",
       "      <td>NaN</td>\n",
       "      <td>김,3천만원,김문수,김지영,김용빈,유상범,이재명,마타,신중한</td>\n",
       "      <td>영국,공직선거 및 선거부정방지법</td>\n",
       "      <td>캐나다,대검찰청,민주당,국회 법사위,헌법연구관,검찰,국회 법제사법위,경찰,더불어민주...</td>\n",
       "      <td>검사,판사,유권자,결정,선거법,삭제,부활,삭제,30년,혐의,공직선거법,위반,재판,이...</td>\n",
       "      <td>후보자,공직선거법,허위사실공표죄,선거법,이재명,허위사실공표,대법원,유권자,위원회,통...</td>\n",
       "      <td>공직선거법 위반 혐의로 재판을 받는 이재명 더불어민주당 대통령 후보는 대법원 전원합...</td>\n",
       "      <td>http://www.hani.co.kr/arti/politics/election/1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.100701e+06</td>\n",
       "      <td>20250523</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>김정모</td>\n",
       "      <td>환경장관 만난 김태흠 충남지사 “청양 부여 지천댐 조속 건설을”</td>\n",
       "      <td>사회&gt;사회일반</td>\n",
       "      <td>지역&gt;강원</td>\n",
       "      <td>지역&gt;충남</td>\n",
       "      <td>재해&gt;자연재해&gt;가뭄</td>\n",
       "      <td>재해&gt;자연재해&gt;홍수</td>\n",
       "      <td>NaN</td>\n",
       "      <td>김완섭,김태흠</td>\n",
       "      <td>정부세종청사,은산면,수원,부여군,태평양,아시아,청양군,장평면,용수,보령댐,대청댐,부...</td>\n",
       "      <td>환경부,정부,부여군,환경부장관,충남지사,충남,보령댐,용수,청양</td>\n",
       "      <td>환경장관,청양,김태흠,충남,지사,부여,건설,지천댐,조속,김태흠,충남,지사,청양,부여...</td>\n",
       "      <td>지천댐,청양,충남,부여,보령댐,후보지,부여군,대청댐,수원,김태흠,환경부,아시아,김완...</td>\n",
       "      <td>김태흠 충남지사가 청양 부여 지천댐 건설을 조속하게 추진해 줄 것을 정부에 요청했다...</td>\n",
       "      <td>http://www.segye.com/content/html/2025/05/22/2...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         뉴스 식별자        일자   언론사     기고자  \\\n",
       "0  1.101001e+06  20250523   한겨레  김남일 기자   \n",
       "1  1.100701e+06  20250523  세계일보     김정모   \n",
       "\n",
       "                                      제목    통합 분류1     통합 분류2  통합 분류3  \\\n",
       "0  검사 판사가 유권자 결정 바꾸는 선거법 ‘삭제→부활→삭제’ 30년사  정치>국회_정당   사회>사건_사고   정치>선거   \n",
       "1    환경장관 만난 김태흠 충남지사 “청양 부여 지천댐 조속 건설을”   사회>사회일반      지역>강원   지역>충남   \n",
       "\n",
       "      사건/사고 분류1    사건/사고 분류2 사건/사고 분류3                                 인물  \\\n",
       "0  범죄>기업범죄>거래제한   재해>자연재해>홍수       NaN  김,3천만원,김문수,김지영,김용빈,유상범,이재명,마타,신중한   \n",
       "1    재해>자연재해>가뭄   재해>자연재해>홍수       NaN                            김완섭,김태흠   \n",
       "\n",
       "                                                  위치  \\\n",
       "0                                  영국,공직선거 및 선거부정방지법   \n",
       "1  정부세종청사,은산면,수원,부여군,태평양,아시아,청양군,장평면,용수,보령댐,대청댐,부...   \n",
       "\n",
       "                                                  기관  \\\n",
       "0  캐나다,대검찰청,민주당,국회 법사위,헌법연구관,검찰,국회 법제사법위,경찰,더불어민주...   \n",
       "1                 환경부,정부,부여군,환경부장관,충남지사,충남,보령댐,용수,청양   \n",
       "\n",
       "                                                 키워드  \\\n",
       "0  검사,판사,유권자,결정,선거법,삭제,부활,삭제,30년,혐의,공직선거법,위반,재판,이...   \n",
       "1  환경장관,청양,김태흠,충남,지사,부여,건설,지천댐,조속,김태흠,충남,지사,청양,부여...   \n",
       "\n",
       "                                   특성추출(가중치순 상위 50개)  \\\n",
       "0  후보자,공직선거법,허위사실공표죄,선거법,이재명,허위사실공표,대법원,유권자,위원회,통...   \n",
       "1  지천댐,청양,충남,부여,보령댐,후보지,부여군,대청댐,수원,김태흠,환경부,아시아,김완...   \n",
       "\n",
       "                                                  본문  \\\n",
       "0  공직선거법 위반 혐의로 재판을 받는 이재명 더불어민주당 대통령 후보는 대법원 전원합...   \n",
       "1  김태흠 충남지사가 청양 부여 지천댐 건설을 조속하게 추진해 줄 것을 정부에 요청했다...   \n",
       "\n",
       "                                                 URL 분석제외 여부  \n",
       "0  http://www.hani.co.kr/arti/politics/election/1...     NaN  \n",
       "1  http://www.segye.com/content/html/2025/05/22/2...     NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2040e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>본문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>검사 판사가 유권자 결정 바꾸는 선거법 ‘삭제→부활→삭제’ 30년사</td>\n",
       "      <td>공직선거법 위반 혐의로 재판을 받는 이재명 더불어민주당 대통령 후보는 대법원 전원합...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>환경장관 만난 김태흠 충남지사 “청양 부여 지천댐 조속 건설을”</td>\n",
       "      <td>김태흠 충남지사가 청양 부여 지천댐 건설을 조속하게 추진해 줄 것을 정부에 요청했다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      제목  \\\n",
       "0  검사 판사가 유권자 결정 바꾸는 선거법 ‘삭제→부활→삭제’ 30년사   \n",
       "1    환경장관 만난 김태흠 충남지사 “청양 부여 지천댐 조속 건설을”   \n",
       "\n",
       "                                                  본문  \n",
       "0  공직선거법 위반 혐의로 재판을 받는 이재명 더불어민주당 대통령 후보는 대법원 전원합...  \n",
       "1  김태흠 충남지사가 청양 부여 지천댐 건설을 조속하게 추진해 줄 것을 정부에 요청했다...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"제목\", \"본문\"]]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4471cf",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6702ac53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['제목'], ['본문']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 : 개별 뉴스 기사(제목 + 본문)\n",
    "tokens = tokenizer(df)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3454eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 + 토큰화 : 소문자 통일, 형태소단위 토큰화\n",
    "\n",
    "# gensim 이용해서 embedding model 학습.\n",
    "\n",
    "# 결과 확인 -> 유사도 검사"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
